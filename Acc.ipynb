{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key: signal\n",
      "  - signal keys: dict_keys(['chest', 'wrist'])\n",
      "    - chest keys: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
      "    - wrist keys: dict_keys(['ACC', 'BVP', 'EDA', 'TEMP'])\n",
      "\n",
      "Key: label\n",
      "  - label shape: (4255300,)\n",
      "\n",
      "Key: subject\n",
      "  - subject: S2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def load_and_explore_pkl(filename):\n",
    "    # Load the pickle file with latin1 encoding\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')  # Use 'latin1' to avoid encoding issues\n",
    "    \n",
    "    # Print a summary of the loaded data\n",
    "    if isinstance(data, dict):\n",
    "        # print(\"Loaded data keys:\")\n",
    "        # print(data.keys())  # Print all keys\n",
    "        \n",
    "        # Print summary of each key\n",
    "        for key in data:\n",
    "            print(f\"\\nKey: {key}\")\n",
    "            if key == 'signal':\n",
    "                print(\"  - signal keys:\", data[key].keys())\n",
    "                print(\"    - chest keys:\", data[key]['chest'].keys())\n",
    "                print(\"    - wrist keys:\", data[key]['wrist'].keys())\n",
    "            elif key == 'label':\n",
    "                print(\"  - label shape:\", data[key].shape)\n",
    "            else:\n",
    "                print(f\"  - {key}:\", data[key])\n",
    "    else:\n",
    "        print(\"Loaded data is not a dictionary\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "filename = \"../S2/S2.pkl\"  # Replace with the relative path to your actual .pkl filename\n",
    "data = load_and_explore_pkl(filename)\n",
    "# labels = data['label']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Access chest ACC data and labels\n",
    "# chest_acc_data = data['signal']['chest']['ACC']\n",
    "\n",
    "# # Check the shape of the data\n",
    "# print(\"\\nChest ACC data shape:\")\n",
    "# print(chest_acc_data.shape)\n",
    "# print(\"\\nLabels shape:\")\n",
    "# print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label distribution: {0: 2142701, 1: 800800, 2: 430500, 3: 253400, 4: 537599, 6: 45500, 7: 44800}\n"
     ]
    }
   ],
   "source": [
    "labels = data['label']\n",
    "# Inspect the distribution of the original labels\n",
    "\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "label_distribution = dict(zip(unique_labels, counts))\n",
    "\n",
    "print(\"Original label distribution:\", label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered labels length: 1484700\n",
      "Filtered chest ACC length: 1484700\n",
      "Filtered chest ECG length: 1484700\n",
      "Filtered chest EMG length: 1484700\n",
      "Filtered chest EDA length: 1484700\n",
      "Filtered chest Temp length: 1484700\n",
      "Filtered chest Resp length: 1484700\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieve labels\n",
    "labels = data['label']\n",
    "\n",
    "# Define the labels to remove\n",
    "labels_to_remove = {0, 4, 5, 6, 7}\n",
    "\n",
    "# Get indices of the labels to keep\n",
    "indices_to_keep = np.array([i for i, label in enumerate(labels) if label not in labels_to_remove], dtype=int)\n",
    "\n",
    "# Function to filter signal data\n",
    "def filter_signals(signal_data, indices):\n",
    "    return signal_data[indices]\n",
    "\n",
    "# Filter chest data\n",
    "filtered_chest = {modality: filter_signals(np.array(data['signal']['chest'][modality]), indices_to_keep) for modality in data['signal']['chest']}\n",
    "\n",
    "# Filter labels\n",
    "filtered_labels = np.array(labels)[indices_to_keep]\n",
    "\n",
    "# Truncate the filtered chest data and labels to ensure consistency\n",
    "max_length = min(len(filtered_labels), len(filtered_chest['ACC']))\n",
    "\n",
    "truncated_filtered_labels = filtered_labels[:max_length]\n",
    "truncated_filtered_chest = {modality: filtered_chest[modality][:max_length] for modality in filtered_chest}\n",
    "\n",
    "# Update data dictionary with filtered chest data and labels\n",
    "filtered_data = {\n",
    "    'signal': {\n",
    "        'chest': truncated_filtered_chest\n",
    "    },\n",
    "    'label': truncated_filtered_labels\n",
    "}\n",
    "\n",
    "# Verify the lengths after filtering\n",
    "print(f\"Filtered labels length: {len(filtered_data['label'])}\")\n",
    "for modality in filtered_data['signal']['chest']:\n",
    "    print(f\"Filtered chest {modality} length: {len(filtered_data['signal']['chest'][modality])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract variables for each chest modality\n",
    "acc_data = filtered_data['signal']['chest']['ACC']\n",
    "ecg_data = filtered_data['signal']['chest']['ECG']\n",
    "emg_data = filtered_data['signal']['chest']['EMG']\n",
    "eda_data = filtered_data['signal']['chest']['EDA']\n",
    "temp_data = filtered_data['signal']['chest']['Temp']\n",
    "resp_data = filtered_data['signal']['chest']['Resp']\n",
    "\n",
    "# # Print lengths to verify\n",
    "# print(f\"ACC data length: {len(acc_data)}\")\n",
    "# print(f\"ECG data length: {len(ecg_data)}\")\n",
    "# print(f\"EMG data length: {len(emg_data)}\")\n",
    "# print(f\"EDA data length: {len(eda_data)}\")\n",
    "# print(f\"TEMP data length: {len(temp_data)}\")\n",
    "# print(f\"RESP data length: {len(resp_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data and labels:\n",
      "Label 1 samples:\n",
      "  Sample Index: 0\n",
      "    Label: 1\n",
      "    ACC data: [ 0.89139998 -0.11019999 -0.25760001]\n",
      "    ECG data: [0.03094482]\n",
      "    EMG data: [-0.00370789]\n",
      "    EDA data: [5.71098328]\n",
      "    TEMP data: [29.083618]\n",
      "    RESP data: [1.19171143]\n",
      "\n",
      "  Sample Index: 1\n",
      "    Label: 1\n",
      "    ACC data: [ 0.89260006 -0.10860002 -0.25440001]\n",
      "    ECG data: [0.03364563]\n",
      "    EMG data: [-0.0141449]\n",
      "    EDA data: [5.71937561]\n",
      "    TEMP data: [29.122437]\n",
      "    RESP data: [1.13983154]\n",
      "\n",
      "Label 2 samples:\n",
      "  Sample Index: 800800\n",
      "    Label: 2\n",
      "    ACC data: [ 0.87759995 -0.10299999 -0.29680002]\n",
      "    ECG data: [-0.01167297]\n",
      "    EMG data: [0.0050354]\n",
      "    EDA data: [1.27830505]\n",
      "    TEMP data: [31.21051]\n",
      "    RESP data: [-1.222229]\n",
      "\n",
      "  Sample Index: 800801\n",
      "    Label: 2\n",
      "    ACC data: [ 0.87580001 -0.10180002 -0.29519999]\n",
      "    ECG data: [-0.0015564]\n",
      "    EMG data: [0.00059509]\n",
      "    EDA data: [1.25274658]\n",
      "    TEMP data: [31.22229]\n",
      "    RESP data: [-1.20239258]\n",
      "\n",
      "Label 3 samples:\n",
      "  Sample Index: 1231300\n",
      "    Label: 3\n",
      "    ACC data: [ 0.90820003 -0.16119999 -0.10100001]\n",
      "    ECG data: [-0.09645081]\n",
      "    EMG data: [0.01094055]\n",
      "    EDA data: [0.77285767]\n",
      "    TEMP data: [31.667297]\n",
      "    RESP data: [-0.90179443]\n",
      "\n",
      "  Sample Index: 1231301\n",
      "    Label: 3\n",
      "    ACC data: [ 0.90859997 -0.16299999 -0.0966    ]\n",
      "    ECG data: [-0.09159851]\n",
      "    EMG data: [-0.00947571]\n",
      "    EDA data: [0.76065063]\n",
      "    TEMP data: [31.653992]\n",
      "    RESP data: [-1.02081299]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of samples to display per label\n",
    "samples_per_label = 2\n",
    "\n",
    "# Create a dictionary to store samples for each label\n",
    "samples_dict = {1: [], 2: [], 3: []}\n",
    "\n",
    "# Collect samples for each label\n",
    "for i in range(len(filtered_data['label'])):\n",
    "    label = filtered_data['label'][i]\n",
    "    if label in samples_dict and len(samples_dict[label]) < samples_per_label:\n",
    "        samples_dict[label].append(i)\n",
    "    # Stop if we've collected enough samples for all labels\n",
    "    if all(len(samples) >= samples_per_label for samples in samples_dict.values()):\n",
    "        break\n",
    "\n",
    "# Print sample data and labels\n",
    "print(f\"Sample data and labels:\")\n",
    "\n",
    "# Ensure we have the required samples for each label\n",
    "for label in [1, 2, 3]:\n",
    "    print(f\"Label {label} samples:\")\n",
    "    indices = samples_dict[label]\n",
    "    for idx in indices:\n",
    "        print(f\"  Sample Index: {idx}\")\n",
    "        print(f\"    Label: {filtered_data['label'][idx]}\")\n",
    "        print(f\"    ACC data: {acc_data[idx]}\")\n",
    "        print(f\"    ECG data: {ecg_data[idx]}\")\n",
    "        print(f\"    EMG data: {emg_data[idx]}\")\n",
    "        print(f\"    EDA data: {eda_data[idx]}\")\n",
    "        print(f\"    TEMP data: {temp_data[idx]}\")\n",
    "        print(f\"    RESP data: {resp_data[idx]}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.96      0.98    239861\n",
      "           2       0.95      0.96      0.95    129025\n",
      "           3       0.91      0.99      0.95     76524\n",
      "\n",
      "    accuracy                           0.96    445410\n",
      "   macro avg       0.95      0.97      0.96    445410\n",
      "weighted avg       0.97      0.96      0.96    445410\n",
      "\n",
      "Confusion Matrix:\n",
      "[[230531   6206   3124]\n",
      " [  1220 123410   4395]\n",
      " [    34    762  75728]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming 'acc_data' and 'filtered_data['label']' are already defined\n",
    "\n",
    "# Extract features and labels\n",
    "X = np.array(acc_data)  # Features (ACC data)\n",
    "y = np.array(filtered_data['label'])  # Labels\n",
    "\n",
    "# Check dimensions and adjust if necessary\n",
    "if X.ndim == 1:\n",
    "    X = X.reshape(-1, 1)  # Reshape if ACC data is one-dimensional\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define SMOTE and the model\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create a pipeline with SMOTE and Logistic Regression\n",
    "pipeline = Pipeline(steps=[('smote', smote), ('model', model)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
