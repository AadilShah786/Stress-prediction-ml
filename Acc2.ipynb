{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key: signal\n",
      "  - signal keys: dict_keys(['chest', 'wrist'])\n",
      "    - chest keys: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
      "    - wrist keys: dict_keys(['ACC', 'BVP', 'EDA', 'TEMP'])\n",
      "\n",
      "Key: label\n",
      "  - label shape: (4255300,)\n",
      "\n",
      "Key: subject\n",
      "  - subject: S2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_and_explore_pkl(filename):\n",
    "    # Load the pickle file with latin1 encoding\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')  # Use 'latin1' to avoid encoding issues\n",
    "    \n",
    "    # Print a summary of the loaded data\n",
    "    if isinstance(data, dict):\n",
    "        # print(\"Loaded data keys:\")\n",
    "        # print(data.keys())  # Print all keys\n",
    "        \n",
    "        # Print summary of each key\n",
    "        for key in data:\n",
    "            print(f\"\\nKey: {key}\")\n",
    "            if key == 'signal':\n",
    "                print(\"  - signal keys:\", data[key].keys())\n",
    "                print(\"    - chest keys:\", data[key]['chest'].keys())\n",
    "                print(\"    - wrist keys:\", data[key]['wrist'].keys())\n",
    "            elif key == 'label':\n",
    "                print(\"  - label shape:\", data[key].shape)\n",
    "            else:\n",
    "                print(f\"  - {key}:\", data[key])\n",
    "    else:\n",
    "        print(\"Loaded data is not a dictionary\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "filename = \"../S2/S2.pkl\"  # Replace with the relative path to your actual .pkl filename\n",
    "data = load_and_explore_pkl(filename)\n",
    "# labels = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered labels length: 2022299\n",
      "Filtered chest ACC length: 2022299\n",
      "Filtered chest ECG length: 2022299\n",
      "Filtered chest EMG length: 2022299\n",
      "Filtered chest EDA length: 2022299\n",
      "Filtered chest Temp length: 2022299\n",
      "Filtered chest Resp length: 2022299\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieve labels\n",
    "labels = data['label']\n",
    "\n",
    "# Define the labels to remove\n",
    "labels_to_remove = {0,5,6,7}\n",
    "\n",
    "# Get indices of the labels to keep\n",
    "indices_to_keep = np.array([i for i, label in enumerate(labels) if label not in labels_to_remove], dtype=int)\n",
    "\n",
    "# Function to filter signal data\n",
    "def filter_signals(signal_data, indices):\n",
    "    return signal_data[indices]\n",
    "\n",
    "# Filter chest data\n",
    "filtered_chest = {modality: filter_signals(np.array(data['signal']['chest'][modality]), indices_to_keep) for modality in data['signal']['chest']}\n",
    "\n",
    "# Filter labels\n",
    "filtered_labels = np.array(labels)[indices_to_keep]\n",
    "\n",
    "# Truncate the filtered chest data and labels to ensure consistency\n",
    "max_length = min(len(filtered_labels), len(filtered_chest['ACC']))\n",
    "\n",
    "truncated_filtered_labels = filtered_labels[:max_length]\n",
    "truncated_filtered_chest = {modality: filtered_chest[modality][:max_length] for modality in filtered_chest}\n",
    "\n",
    "# Update data dictionary with filtered chest data and labels\n",
    "filtered_data = {\n",
    "    'signal': {\n",
    "        'chest': truncated_filtered_chest\n",
    "    },\n",
    "    'label': truncated_filtered_labels\n",
    "}\n",
    "\n",
    "# Verify the lengths after filtering\n",
    "print(f\"Filtered labels length: {len(filtered_data['label'])}\")\n",
    "for modality in filtered_data['signal']['chest']:\n",
    "    print(f\"Filtered chest {modality} length: {len(filtered_data['signal']['chest'][modality])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract variables for each chest modality\n",
    "acc_data = filtered_data['signal']['chest']['ACC']\n",
    "ecg_data = filtered_data['signal']['chest']['ECG']\n",
    "emg_data = filtered_data['signal']['chest']['EMG']\n",
    "eda_data = filtered_data['signal']['chest']['EDA']\n",
    "temp_data = filtered_data['signal']['chest']['Temp']\n",
    "resp_data = filtered_data['signal']['chest']['Resp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.95      0.96    240492\n",
      "           2       0.95      0.96      0.95    128782\n",
      "           3       0.91      0.99      0.95     76104\n",
      "           4       0.98      0.98      0.98    161312\n",
      "\n",
      "    accuracy                           0.96    606690\n",
      "   macro avg       0.95      0.97      0.96    606690\n",
      "weighted avg       0.96      0.96      0.96    606690\n",
      "\n",
      "Confusion Matrix:\n",
      "[[227302   6282   3109   3799]\n",
      " [  1226 123281   4275      0]\n",
      " [    35    827  75242      0]\n",
      " [  3140      0      0 158172]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming 'acc_data' and 'filtered_data['label']' are already defined\n",
    "\n",
    "# Extract features and labels\n",
    "X = np.array(acc_data)  # Features (ACC data)\n",
    "y = np.array(filtered_data['label'])  # Labels\n",
    "\n",
    "# Check dimensions and adjust if necessary\n",
    "if X.ndim == 1:\n",
    "    X = X.reshape(-1, 1)  # Reshape if ACC data is one-dimensional\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define SMOTE and the model\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create a pipeline with SMOTE and Logistic Regression\n",
    "pipeline = Pipeline(steps=[('smote', smote), ('model', model)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Function to predict label from manual input\n",
    "def predict_label(acc_values):\n",
    "    # Standardize the input data\n",
    "    acc_values_scaled = scaler.transform([acc_values])\n",
    "    \n",
    "    # Predict the label\n",
    "    predicted_label = pipeline.predict(acc_values_scaled)\n",
    "    \n",
    "    return predicted_label[0]\n",
    "\n",
    "# Example manual input values (replace these with actual values)\n",
    "manual_acc_values = [ 0.87580001, -0.10180002 ,-0.29519999 ]  # Replace with actual ACC values\n",
    "\n",
    "# Predict the label\n",
    "predicted_label = predict_label(manual_acc_values)\n",
    "\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
